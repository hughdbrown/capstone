{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import simplejson\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_germanwings():\n",
    "    filename = \"../data/germanwings.pkl\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "german_wings = load_germanwings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loader(filespec):\n",
    "    for filename in glob.glob(filespec):\n",
    "        print(filename)\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                d = simplejson.loads(line)\n",
    "                doc = {\n",
    "                    \"short_url\": d[\"g\"],\n",
    "                    \"country\": d.get(\"c\", \"\"),\n",
    "                    \"timestamp\": datetime.utcfromtimestamp(d[\"t\"]),\n",
    "                    \"timezone\": d.get(\"tz\", \"\"),\n",
    "                }\n",
    "                if doc[\"short_url\"] in german_wings:\n",
    "                    yield doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading timezones\n",
      "Loading country codes\n"
     ]
    }
   ],
   "source": [
    "from csv import DictReader, register_dialect\n",
    "\n",
    "def load_remapped_timezones():\n",
    "    print(\"Loading timezones\")\n",
    "    with open(\"../data/timezone-map.csv\") as f:\n",
    "        reader = DictReader(f, fieldnames=[\"timezone\", \"offset1\", \"offset2\"])\n",
    "        return {row[\"timezone\"]: row[\"offset1\"] for row in reader}\n",
    "\n",
    "\n",
    "def load_remapped_country_codes():\n",
    "    print(\"Loading country codes\")\n",
    "    dialect = register_dialect('tabs', delimiter='\\t')\n",
    "    with open(\"../data/country-code-lookup.csv\") as f:\n",
    "        reader = DictReader(f, dialect='tabs')\n",
    "        return {row[\"Code\"]: row[\"Country name\"] for row in reader}\n",
    "\n",
    "\n",
    "remapped_timezone = load_remapped_timezones()\n",
    "remapped_country_code = load_remapped_country_codes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GERMANWINGS_PICKLE = \"../data/germanwings-hist.pkl\"\n",
    "\n",
    "\n",
    "def save_germanwings():\n",
    "    print(\"Loading log files\")\n",
    "    df = DataFrame(loader(\"../data-capstone/*.log\"))\n",
    "    print(\"Adding columns to DataFrame\")\n",
    "    # http://stackoverflow.com/questions/24216425/adding-a-new-pandas-column-with-mapped-value-from-a-dictionary\n",
    "    df[\"timezone_offset\"] = df.timezone.map(remapped_timezone.get)\n",
    "    df[\"country_name\"] = df.country.map(remapped_country_code.get)\n",
    "    # http://stackoverflow.com/questions/25146121/extracting-just-month-and-year-from-pandas-datetime-column-python\n",
    "    df[\"day\"] = df.timestamp.dt.day\n",
    "    df[\"hour\"] = df.timestamp.dt.hour\n",
    "    df[\"minute\"] = df.timestamp.dt.minute\n",
    "    print(\"Saving data to pickle file\")\n",
    "    df.to_pickle(GERMANWINGS_PICKLE)\n",
    "    print(\"Done\")\n",
    "    return df\n",
    "\n",
    "def load_germanwings():\n",
    "    return pd.read_pickle(GERMANWINGS_PICKLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = load_germanwings()\n",
    "# df = save_germanwings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_as_loadable_JSON(df, json_filename, column_remapping):\n",
    "    with open(json_filename, \"w\") as f:\n",
    "        df_tmp = df.rename(columns=column_remapping)\n",
    "        objs = [dict(row) for _, row in df_tmp.iterrows()]\n",
    "        f.write(simplejson.dumps(objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TIME_COLUMNS = [\"day\", \"hour\", \"minute\"]\n",
    "COUNTRY_DF_COLUMNS = [\"country_name\"] + TIME_COLUMNS\n",
    "TIMEZONE_COLUMNS = [\"timezone_offset\"] + TIME_COLUMNS\n",
    "\n",
    "\n",
    "def country_selection_df(df, countries):\n",
    "    tmp = df[df.country.isin(countries)]\n",
    "    s = pd.Series(tmp.groupby(COUNTRY_DF_COLUMNS).count().timezone, name='count')\n",
    "    return DataFrame(s).reset_index()\n",
    "\n",
    "def make_US_CA(df):\n",
    "    countries = [\"US\", \"CA\"]\n",
    "    return country_selection_df(df, countries)\n",
    "\n",
    "df_US_CA = make_US_CA(df)\n",
    "save_as_loadable_JSON(df_US_CA, \"urlhist_US_CA.json\", {'country_name': 'key'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_US_DE_ES_FR_IT(df):\n",
    "    countries = [\"US\", \"DE\", \"ES\", \"IT\", \"FR\"]\n",
    "    return country_selection_df(df, countries)\n",
    "\n",
    "df_US_DE_ES_FR_IT = make_US_DE_ES_FR_IT(df)\n",
    "save_as_loadable_JSON(df_US_DE_ES_FR_IT, \"urlhist_US_DE_ES_FR_IT.json\", {'country_name': 'key'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_timezone_offset(df):\n",
    "    s = pd.Series(df.groupby(TIMEZONE_COLUMNS).count().timezone, name='count')\n",
    "    df_timezone_offset = DataFrame(s)\n",
    "    df_timezone_offset.reset_index(inplace=True)\n",
    "    return df_timezone_offset\n",
    "\n",
    "df_timezone = make_timezone_offset(df)\n",
    "save_as_loadable_JSON(df_timezone, \"urlhist_timezone_offset.json\", {'timezone_offset': 'key'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def short_url_aggregator(df, date_range=None, countries=None, timezones=None):\n",
    "    tmp = df.copy()\n",
    "    if date_range:\n",
    "        start, end = tuple(pd.to_datetime(item) for item in date_range)\n",
    "        tmp = tmp.query('@start <= timestamp < @end')\n",
    "    if countries:\n",
    "        tmp = tmp[tmp.country.isin(countries)]\n",
    "    if timezones:\n",
    "        tmp = tmp[tmp.timezone.isin(timezones)]\n",
    "    s = pd.Series(tmp.groupby(\"short_url\").count().timezone, name='count')\n",
    "    return DataFrame(s).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = short_url_aggregator(df, date_range=[\"2015-03-25\", \"2015-03-26\"], countries=[\"CA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US - 2015-03-25\n",
      "US - 2015-03-26\n",
      "US - 2015-03-27\n",
      "CA - 2015-03-25\n",
      "CA - 2015-03-26\n",
      "CA - 2015-03-27\n",
      "DE - 2015-03-25\n",
      "DE - 2015-03-26\n",
      "DE - 2015-03-27\n",
      "IT - 2015-03-25\n",
      "IT - 2015-03-26\n",
      "IT - 2015-03-27\n",
      "ES - 2015-03-25\n",
      "ES - 2015-03-26\n",
      "ES - 2015-03-27\n",
      "FR - 2015-03-25\n",
      "FR - 2015-03-26\n",
      "FR - 2015-03-27\n"
     ]
    }
   ],
   "source": [
    "d25, d26, d27, d28 = tuple(\"2015-03-2{0}\".format(x) for x in (5, 6, 7, 8))\n",
    "\n",
    "for country in [\"US\", \"CA\", \"DE\", \"IT\", \"ES\", \"FR\"]:\n",
    "    for dates in [[d25, d26], [d26, d27], [d27, d28]]:\n",
    "        print(\"{0} - {1}\".format(country, dates[0]))\n",
    "        filename = \"short_url_count-{0}-{1}.json\".format(country, dates[0])\n",
    "        x = short_url_aggregator(df, countries=[country], date_range=dates)\n",
    "        filename = \"short_url_count-{0}-{1}.json\".format(country, dates[0])\n",
    "        with open(filename, \"w\") as f:\n",
    "            objs = [dict(row) for _, row in x.iterrows()]\n",
    "            objs = {d[\"short_url\"]: d[\"count\"] for d in objs}\n",
    "            f.write(simplejson.dumps(objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
